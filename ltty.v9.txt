!pip install catboost
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor, StackingRegressor
from sklearn.linear_model import BayesianRidge
from catboost import CatBoostRegressor
from sklearn.multioutput import MultiOutputRegressor

def preprocess_data(data):
    data = data.drop(["PRODUCT", "DRAW NUMBER", "SEQUENCE NUMBER"], axis=1)
    data["DRAW DATE"] = pd.to_datetime(data["DRAW DATE"])
    data = data.drop(["DRAW DATE"], axis=1)
    return data

def rolling_average(data, window):
    return data.rolling(window=window).mean().fillna(0)

def differences(data):
    return data.diff().fillna(0)

def count_occurrences(data, window):
    return data.rolling(window=window).apply(lambda x: np.sum(x)).fillna(0)

def cumulative_sum(data):
    return data.cumsum()

def calculate_enhanced_frequencies(data):
    enhanced_frequency_data = []
    numbers = [f"NUMBER DRAWN {i}" for i in range(1, 7)]
    bonus_numbers = ["BONUS NUMBER"]

    for index, row in data.iterrows():
        draw_numbers = row[numbers].values
        draw_bonus_numbers = row[bonus_numbers].values
        frequencies = np.zeros(49)
        bonus_frequencies = np.zeros(49)

        for number in draw_numbers:
            frequencies[number - 1] += 1

        for number in draw_bonus_numbers:
            bonus_frequencies[number - 1] += 1

        rolling_avg_5 = rolling_average(pd.Series(frequencies), 5)
        rolling_avg_10 = rolling_average(pd.Series(frequencies), 10)
        rolling_avg_20 = rolling_average(pd.Series(frequencies), 20)

        diff = differences(pd.Series(frequencies))

        count_occ_5 = count_occurrences(pd.Series(frequencies), 5)
        count_occ_10 = count_occurrences(pd.Series(frequencies), 10)
        count_occ_20 = count_occurrences(pd.Series(frequencies), 20)

        cum_sum = cumulative_sum(pd.Series(frequencies))

        enhanced_features = np.concatenate([
            frequencies,
            bonus_frequencies,
            rolling_avg_5,
            rolling_avg_10,
            rolling_avg_20,
            diff,
            count_occ_5,
            count_occ_10,
            count_occ_20,
            cum_sum
        ])

        enhanced_frequency_data.append(enhanced_features)

    column_names = [f"EF_{i}" for i in range(1, len(enhanced_features) + 1)]
    return pd.DataFrame(enhanced_frequency_data, columns=column_names)

def train_and_evaluate(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    estimators = [
        ("bayesian_ridge", BayesianRidge()),
        ("catboost", CatBoostRegressor(silent=True)),
        ("random_forest", RandomForestRegressor(random_state=42))
    ]

    stacked_model = StackingRegressor(estimators=estimators, final_estimator=BayesianRidge(), cv=5)
    multioutput_stacked_model = MultiOutputRegressor(stacked_model)
    multioutput_stacked_model.fit(X_train, y_train)

    y_pred = multioutput_stacked_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    print(f"Mean squared error: {mse}")

    return multioutput_stacked_model

def get_unique_numbers(prediction):
    unique_numbers = np.unique(np.round(prediction))
    while len(unique_numbers) < len(prediction):
        idx = np.argmin(prediction)
        prediction[idx] += 1
        unique_numbers = np.unique(np.round(prediction))
    return unique_numbers

# Prompt to upload the updated file
from google.colab import files
uploaded = files.upload()

import io
data = pd.read_csv(io.BytesIO(uploaded[next(iter(uploaded))]))

data = preprocess_data(data)

X = calculate_enhanced_frequencies(data)
y_6 = data[["NUMBER DRAWN 1", "NUMBER DRAWN 2", "NUMBER DRAWN 3", "NUMBER DRAWN 4", "NUMBER DRAWN 5", "NUMBER DRAWN 6"]]
y_bonus = data[["BONUS NUMBER"]]

# Train and evaluate for 6/6 prediction
print("6/6 Prediction:")
model_6 = train_and_evaluate(X, y_6)

# Train and evaluate for 5 most likely numbers
print("\n5 most likely numbers Prediction:")
model_5 = train_and_evaluate(X, y_6.iloc[:, :5])

# Train and evaluate for bonus number prediction
print("\nBonus number Prediction:")
model_bonus = train_and_evaluate(X, y_bonus)

# Train and evaluate for 6/6/Split prediction
print("\n6/6/Split Prediction:")
y_6_split_1 = data[["NUMBER DRAWN 1", "NUMBER DRAWN 2", "NUMBER DRAWN 3"]]
y_6_split_2 = data[["NUMBER DRAWN 4", "NUMBER DRAWN 5", "NUMBER DRAWN 6"]]
model_split_1 = train_and_evaluate(X, y_6_split_1)
model_split_2 = train_and_evaluate(X, y_6_split_2)

# Predict the next draw
next_draw_6 = model_6.predict([X.iloc[-1]])[0]
next_draw_5 = model_5.predict([X.iloc[-1]])[0]
next_draw_bonus = model_bonus.predict([X.iloc[-1]])[0]

next_draw_split_1 = model_split_1.predict([X.iloc[-1]])[0]
next_draw_split_2 = model_split_2.predict([X.iloc[-1]])[0]

unique_numbers_6 = get_unique_numbers(next_draw_6)
unique_numbers_5 = get_unique_numbers(next_draw_5)[:5]

unique_numbers_split_1 = get_unique_numbers(next_draw_split_1)


unique_numbers_split_2 = get_unique_numbers(next_draw_split_2)
unique_numbers_6_split = np.concatenate((unique_numbers_split_1, unique_numbers_split_2))

bonus_number = np.round(next_draw_bonus)[0]

print("\nNext draw 6/6 prediction:", unique_numbers_6)
print("Next draw 5 most likely numbers prediction:", unique_numbers_5)
print("Next draw bonus number prediction:", bonus_number)
print("Next draw 6/6/Split prediction:", unique_numbers_6_split)